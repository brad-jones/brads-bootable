# yaml-language-server: $schema=https://taskfile.dev/schema.json
# https://taskfile.dev
version: "3"

dotenv: [".env"]

tasks:
  init:
    desc: Setup local dev env (executed automatically by pixi)
    cmds:
      - lefthook install -f
      - git config pull.rebase true
      - git config core.editor "code --wait"
      - git config commit.template "$PWD/.gitmsgtpl"
      - kubectx mini1

  build:image:
    desc: Builds the OCI image that bootc will turn into a bootable ISO.
    cmds:
      - docker build -t ghcr.io/brad-jones/brads-bootable:dev ./src

  pull:iso:
    desc: Downloads the latest bootable ISO from ghcr.io
    summary: |
      Use something like https://etcher.balena.io/ to flash it to media.
      https://www.ventoy.net/ also works well.

      Then boot off this and it will automatically install.
      WARNING: It will without prompting format all nvme disks!
    cmds:
      - oras pull ghcr.io/brad-jones/brads-bootable/iso:latest -o ./iso

  copy:config:
    desc: Copies the K8s config/certs down to our local dev env
    summary: |
      This is a temporary measure until we get some sort of proper OIDC setup.
    cmds:
      - deno run -qA ./.tasks/kubeconfig-copier.ts

  apply:
    desc: Directly runs pulumi against the cluster instead of indirectly via goj
    dir: ./k8s
    vars:
      PULUMI_KEY:
        sh: gopass -o brads-bootable/pulumi.key
    env:
      PULUMI_CONFIG_PASSPHRASE: "{{.PULUMI_KEY}}"
      PULUMI_K8S_ENABLE_SERVER_SIDE_APPLY: true
      PULUMI_BACKEND_URL: file://./backend
    cmds:
      - kubectx mini1
      - mkdir -p ./backend
      - >-
          sshfs brad-jones@192.168.254.4:/var/goj/state/backend ./backend
          -o sftp_server="/usr/bin/sudo -u root /usr/libexec/openssh/sftp-server"
      - defer: umount ./backend
      - pulumi up -s brads-cluster

  goj:init:
    desc: After firstboot, run this to inject secrets to allow further cluster configuration via a Pulumi stack.
    vars:
      PULUMI_KEY:
        sh: gopass -o brads-bootable/pulumi.key
      GH_TOKEN:
        sh: gopass -o brads-bootable/gh.token
    cmds:
      - kubectl --context mini1 -n goj-system create secret generic goj-git-bearer-token --from-literal=value={{.GH_TOKEN}}
      - kubectl --context mini1 -n goj-system create secret generic goj-pulumi-key --from-literal=value="{{.PULUMI_KEY}}"

  goj:run:
    desc: Run GitOpsJob on demand instead of waiting for the cron schedule.
    vars:
      JOB:
        sh: echo "git-ops-job-$(tr -dc a-z0-9 </dev/urandom | head -c 13; echo)"
    cmds:
      - kubectl --context mini1 -n goj-system create job {{.JOB}} --from=cronjob/git-ops-cron-job
      - kubectl --context mini1 -n goj-system wait --for=condition=Ready pod -l=job-name={{.JOB}}
      - kubectl --context mini1 -n goj-system logs -f job/{{.JOB}}

  goj:test:
    desc: Same as task goj:install && task goj:run, useful while working on goj it's self
    cmds:
      - task: goj:install
      - task: goj:run

  goj:reinstall:
    desc: Reinstalls GitOpsJob, useful while working on goj it's self
    cmds:
      - kubectl --context mini1 delete namespace/goj-system || true
      - kubectl --context mini1 wait --for=delete namespace/goj-system --timeout=60s
      - kubectl --context mini1 apply -f ./src/var/lib/k0s/manifests/goj/install.yaml
      - task: goj:init

  goj:clear:
    desc: Deletes all jobs from the goj-system namespace
    cmds:
      - kubectl delete jobs -n goj-system --all

  goj:suspend:
    desc: Suspends the automated cronjob, useful when applying the pulumi stack directly
    vars:
      PATCH: '{"spec":{"suspend":true}}'
    cmds:
      - kubectl --context mini1 -n goj-system patch cronjobs git-ops-cron-job -p '{{.PATCH}}'

  goj:resume:
    desc: Resumes the automated cronjob.
    vars:
      PATCH: '{"spec":{"suspend":false}}'
    cmds:
      - kubectl --context mini1 -n goj-system patch cronjobs git-ops-cron-job -p '{{.PATCH}}'
